{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netze zur Dokumentenklassifikation mit Keras\n",
    "\n",
    "## Daniel Ringler\n",
    "\n",
    "## Ancud IT-Beratung: [ancud.de](https://ancud.de)\n",
    "\n",
    "![ancud](img/ancud_website.png)\n",
    "\n",
    "### This talk:  [github.com/dringler/talks/blob/master/data-analytics-2018/dl-keras.ipynb](https://github.com/dringler/talks/blob/master/data-analytics-2018/dl-keras.ipynb) \n",
    "(based on Adrin Jalali's talk https://github.com/adrinjalali/2017-05-talk-dl)\n",
    "\n",
    "### Requirements: python3, ipython, jupyter notebook, conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "\n",
    "## Human Brain\n",
    "\n",
    "![human NN](img/biological_NN.png)\n",
    "\n",
    "## Artificial Neural Networks\n",
    "* *\"A logical calculus of the ideas imminent in nervous activity\"* by Warren S. McCulloch and Walter Pitts (1943)\n",
    "* \"computational model based on the brain\"\n",
    "* parallel processing of input through a network of nodes\n",
    "* complex **adaptive** system: ability to *learn* by adjusting the *weights*\n",
    "* errors alter the weights to improve the results\n",
    "* **neurons:** read and process input, and generate output\n",
    "* strategies for learning:\n",
    "    * **supvervised:** labeled training data\n",
    "    * **unsupervised:** \n",
    "    * **reinforcement:** learn by observation\n",
    "    \n",
    "![artificial NN](img/artificial_NN.png)\n",
    "\n",
    "### Perceptron\n",
    "* Simplest neural network with a single neuron\n",
    "    * One or more inputs with weights\n",
    "    * Processor with activation function\n",
    "    * Single output\n",
    "* Feed forward model: from left to right\n",
    "\n",
    "![perceptron](img/perceptron_weights.png)\n",
    "\n",
    "#### Adding Bias to the Perceptron\n",
    "\n",
    "![perceptron](img/perceptron_weights_bias.png)\n",
    "\n",
    "\n",
    "#### Example\n",
    "\n",
    "![perceptron example](img/perceptron_example.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Source: The Nature of Code by Daniel Shiffman: https://natureofcode.com/book/chapter-10-neural-networks/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Keras 4 Step Workflow](https://www.kdnuggets.com/2018/06/keras-4-step-workflow.html)\n",
    "\n",
    "![keras-workflow](img/keras-4-step-workflow.png)\n",
    "\n",
    " 1. **Define training data:** load, clean, preprocess\n",
    " 2. **Define NN model:** using the sequential model class or functional API in Keras\n",
    "    * Sequential: linear stack of networks layers\n",
    "    * Functional API: flexibel approach for more complex models (e.g. multi-input, multi-output, or graph models)\n",
    " 3. **Configure learning process:** *compile()* method\n",
    "    * optimizer, loss function, list of metrics in sequential model class\n",
    "    * optimizer, loss function, loss weights for functional API\n",
    " 4. **Train model:** *fit()* method \n",
    "    * input and target tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a virtual environment with conda with keras\n",
    "\n",
    " conda create -n keras_env [nb_conda](https://github.com/Anaconda-Platform/nb_conda) [keras](https://github.com/keras-team/keras)\n",
    " \n",
    "* with nb_conda the created virtual environment can be selected as a kernel in the jupyter notebook\n",
    "* keras will also install all required packages such as tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/keras-team/keras/blob/master/examples/reuters_mlp.py\n",
    "'''Trains and evaluate a simple MLP\n",
    "on the Reuters newswire topic classification task.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = reuters.load_data(num_words=max_words,\n",
    "                                                         #num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "print(len(x_train_data), 'train sequences')\n",
    "print(len(x_test_data), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train_data) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word to index mapping\n",
    "word_index = reuters.get_word_index()\n",
    "# Reverse mapping: index to word\n",
    "index_word = {i: w for w, i in word_index.items()} \n",
    "index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'federal',\n",
       " 'gain',\n",
       " 'development',\n",
       " 'foreign',\n",
       " 'lt',\n",
       " 'any',\n",
       " 'year',\n",
       " 'reuter',\n",
       " 'revs',\n",
       " 'year',\n",
       " 'an',\n",
       " 'billion',\n",
       " 'billion',\n",
       " 'vs',\n",
       " 'reuter',\n",
       " 'from',\n",
       " 'dlrs',\n",
       " 'vs',\n",
       " 'may',\n",
       " 'reserves',\n",
       " 'were',\n",
       " 'vs',\n",
       " 'reuter',\n",
       " 'point',\n",
       " 'were',\n",
       " 'vs',\n",
       " 'pct',\n",
       " 'dlrs']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_word[i] for i in x_train_data[23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 217us/step - loss: 1.4296 - acc: 0.6791 - val_loss: 1.0885 - val_acc: 0.7642\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 174us/step - loss: 0.7888 - acc: 0.8191 - val_loss: 0.9403 - val_acc: 0.7864\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 0.5507 - acc: 0.8660 - val_loss: 0.8916 - val_acc: 0.7998\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.4172 - acc: 0.8973 - val_loss: 0.8787 - val_acc: 0.8065\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 178us/step - loss: 0.3243 - acc: 0.9172 - val_loss: 0.9123 - val_acc: 0.7964\n",
      "2246/2246 [==============================] - 0s 31us/step\n",
      "Test score: 0.8883000547505868\n",
      "Test accuracy: 0.7916295636687445\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train_data, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test_data, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train_data, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_data, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
